---
title: "Modelos de regressão para variáveis positivas"
author: "Gabriel Stein 197466, Gabriela Vechini 172625"
output:
  beamer_presentation:
    theme: "default"
    colortheme: "seahorse"
    fig_crop: no
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage[brazil, english, portuguese]{babel}
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage[fixlanguage]{babelbib}
  - \usepackage{times}

  - \usepackage{graphicx}
  - \usepackage{wrapfig}
  - \usepackage{pdfpages}
  
  - \usepackage{amsfonts}
  - \usepackage{amssymb}
  - \usepackage{amsmath}
  
  - \usepackage{fancyhdr}
  - \usepackage{subcaption}
  - \usepackage{booktabs}
  - \usepackage{caption}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE,
  digits=3
  )
options(
  OutDec = ",", 
  knitr.table.format = "latex", 
  xtable.comment = FALSE
  )
```

```{r}
library(MASS)
library(HoRM)
library(tidyverse)
library(survival)
library(insuranceData)
library(magrittr)
library(readxl)
library(corrplot)
library(haven)
library(fitdistrplus)
library(ssym)
library(gridExtra)
library(knitr)
library(kableExtra)
library(formattable)
library(statmod)
library(ggfortify)
library(qqplotr)
library(vctrs)
source("diag_norm.R")
source("envel_norm.R")
```

```{r}
data(Snacks)
snacks <- Snacks %>% as_tibble() %>% mutate(type = case_when(type == 1 ~ "A",
                                                             type == 2 ~ "B",
                                                             type == 3 ~ "C",
                                                             type == 4 ~ "D",
                                                             type == 5 ~ "E"))
```

## Introdução: Variáveis positivas
	
- Variáveis respostas positivas.
- Precisam ser positivas para estarem dentro do suporte das distribuições que serão supostas.
- Emglobam números interiros e contínuos.
	
## Exemplos de distribuições e suas ultilizações

- Poisson: dados de contagem, poucos zeros, números inteiros positivos;
- Binomial: poucos zero, números inteiros positivos;
- Binomial Negativa: muitos zeros, números inteiros positivos;
- Weibull: base de dados pequena, valores continuos, reais positivos;
- Birnbaum-Saunders: dados assimétricos, poucos zeros, números reais positivos;
- Gama: dados assimétricos, poucos zeros, números reais positivos;
- Normal-Inversa: dados assimétricos, poucos zeros, números reais positivos;

## Dados 

- Foi realizado um experimento de desenvolvimento de produto no Departamento de Nutrição da Faculdade de Saúde Públida da USP com 5 formas de um alimento. Em que a gordua vegetal hidrogenada foi subtitíuda por óleo de carnola.
- Formas: A (22% de gordura, 0%
de óleo de canola), B (0% de gordura, 22% de óleo de canola), C (17% de
gordura, 5% de óleo de canola), D (11% de gordura, 11% de óleo de canola)
e E (5% de gordura, 17% de óleo de canola).
- O experimento foi realizado ao longo de 20 semanas, em cada semana par 15 embalagens de cada tipo de produto era análisado em laboratório.
- Aqui vamos estudar o comportamento da textura através da força necessária para o cisalhamento.

## Banco de dados

```{r}
snacks %>% head(8) %>% set_colnames(c("Cisalhamento","Forma","Semana")) %>%
  kable("latex", booktabs = T, caption = "Primeiras 8 linhas do banco de dados") %>% kable_styling(font_size = 9)
```

## Análise exploratória por forma

```{r}
snacks %>% ggplot(aes(y = texture, x = type)) + geom_boxplot() +
  labs(x = "Forma", y = "Cisalhamento")
```

## Análise exploratória por forma

```{r}
sumario.forma <- snacks %>% group_by(type) %>% summarise(media = mean(texture), dp = sd(texture), cv = dp/media) %>%
  mutate(cv = percent(as.numeric(cv))) %>%
  set_colnames(c("Grupo", "Média", "DP", "CV")) %>% t() 
colnames(sumario.forma) <- sumario.forma[1,]
sumario.forma <- sumario.forma[-1,]
kable(sumario.forma,"latex", booktabs = T) %>% kable_styling(font_size = 9)
```

## Análise exploratória por semana

```{r}
snacks %>% ggplot(aes(y = texture, x = factor(week))) + geom_boxplot() +
  labs(x = "Semana", y = "Cisalhamento")
```

## Análise exploratória por semana

```{r}
sumario.semana <- snacks %>% group_by(week) %>% summarise(media = mean(texture), dp = sd(texture), cv = dp/media) %>%
  mutate(cv = percent(as.numeric(cv))) %>%
  set_colnames(c("Grupo", "Média", "DP", "CV")) %>% t() 
colnames(sumario.semana) <- as.integer(sumario.semana[1,])
sumario.semana <- sumario.semana[-1,]
kable(sumario.semana[,1:5],"latex", booktabs = T) %>% kable_styling(font_size = 8)
kable(sumario.semana[,6:10],"latex", booktabs = T) %>% kable_styling(font_size = 8)
```

<!-- \begin{table}[H] -->
<!-- \centering\begingroup\fontsize{8}{11}\selectfont -->

<!-- \begin{tabular}{lrrrrr} -->
<!-- \hline -->
<!--   & 2 & 4 & 6 & 8 & 10\\ -->
<!-- \hline -->
<!-- Média & 50,9513333 & 44,6588000 & 50,0828000 & 55,5653333 & 60,1502667\\ -->
<!-- DP & 13,1233342 & 9,7580618 & 15,9687690 & 16,2805286 & 14,7190660\\ -->
<!-- CV & 0,2575661 & 0,2185026 & 0,3188474 & 0,2929979 & 0,2447049\\ -->
<!-- \hline -->
<!--   & 12 & 14 & 16 & 18 & 20\\ -->
<!-- \hline -->
<!-- Média & 57,8350667 & 71,571733 & 65,1784000 & 60,3740000 & 52,4552000\\ -->
<!-- DP & 13,6111127 & 20,168339 & 16,9516530 & 10,2482286 & 12,5844843\\ -->
<!-- CV & 0,2353436 & 0,281792 & 0,2600808 & 0,1697457 & 0,2399092\\ -->
<!-- \end{tabular} -->
<!-- \endgroup{} -->
<!-- \end{table} -->

## Análise exploratória por semana e por forma

```{r}
snacks %>% ggplot(aes(y = texture, x = week)) + geom_point() + facet_wrap(~ type) +
  labs(x = "Semana", y = "Cisalhamento")
```

## Modelo normal

Suposições:

- Normalidade
- Homocedasticidade
- Independencia

Modelo:

$$ Y_{ijk} = \alpha_i +  \alpha_i\beta\cos(f(x_{j})) + \varepsilon_{ijk}$$

Onefe $Y_{ijk}$ a força de cisalhamento da $k$-ésima réplica do $i$-ésimo grupo na $j$-ésima semana, onde $k = 1,...,15$, $k = 2,4,6,...,20$ e $i = 1(A),2(B),3(C),4(D),5(E)$, $x_j$ é a $j$-ésima semana, $\alpha_i$ são os efeitos das formas, $\alpha_i\beta$ o efeito da semana interagindo com com o tipo e $\varepsilon_{ijk} \sim N(0,\sigma^2)$ o erro.


```{r}
snacks.fit.normal <- snacks %>% mutate(week.cos = cos((-pi*week + 14*pi)/10)) %>%
  lm(texture ~ -1 + type * week.cos, .)
```

## Diágnóstico Para Modelo Normal

```{r}
diagnorm(snacks.fit.normal)
```

## Alternativa

A força de cisalhamento é uma variável positiva e tem uma distribuição assimétrica à direitra, o que indica que ela pode ser modelada por um distribuição normal inversa ou gama.
Aparentemente a resposta dado a semana tem uma resposta periódica.

Seja $Y_{ijk}$ a força de cisalhamento da $k$-ésima réplica do $i$-ésimo grupo na $j$-ésima semana, onde $k = 1,...,15$, $k = 2,4,6,...,20$ e $i = 1(A),2(B),3(C),4(D),5(E)$. Suponha $Y_{ijk} \sim G(\mu_{ij}\phi)$ e $Y_{ijk} \sim NI(\mu_{ij}\phi)$ e sua parte sistemática

$$ \mu_{ij} = \alpha_i + \beta\cos(ax_j+b)$$

em que $x_j$ é a $j$-ésima semana, $\alpha_i$ são os efeitos das formas, $\beta$ o efeito da semana e $a$ e $b$ foram escolhidos empiricamente.

```{r}
# snacks.fit.gamma.lin <- snacks %>%
#   glm(texture ~ type + week, family = Gamma(link = "identity"), .)
# summary(snacks.fit.gamma)
```

## Gamma

Função de probabilidade

$$f(y_{ijk},\mu_{ij},\phi) = exp[\phi\{-y/u_{ij} - log\mu_{ij}\}-log\Gamma(\phi)+\phi log(\phi y) - logy]$$

Suposições:

- $Y_{ijk} \sim Gama(\mu_{ij}\phi)$
- Indepência das observações
- Parâmetro de precisão $\phi$ constante

## Estimação dos parâmetros do modelo Gama

```{r}
snacks.fit.gamma.cos <- snacks %>% mutate(week.cos = cos((-pi*week + 14*pi)/10)) %>%
  glm(texture ~ -1 + type + week.cos, family = Gamma(link = "identity"), .)
param.gamma <- snacks.fit.gamma.cos %>% broom::tidy() %>%
  mutate(lower = estimate - std.error*1.96, upper = estimate + std.error*1.96) %>%
  mutate_if(is.numeric, funs(round(.,3))) %>%
  mutate(IC = paste("[",lower,";",upper,"]"),
                    p.value = if_else(p.value < 0.001, "< 0.001", as.character(p.value))) %>%
  dplyr::select(1:3,IC,statistic, p.value) %>%
  set_colnames(c("Termo", "Estimatica", "Erro Padrão", "IC (95%)", "Estatística t", "p-valor")) %>%
  kable("latex", booktabs = T) %>% kable_styling(font_size = 8)
dispersao.gamma <- round(summary(snacks.fit.gamma.cos)$dispersion, 4)
aic.gamma <- round(snacks.fit.gamma.cos$aic)
```

\begin{table}[H]
\centering\begingroup\fontsize{8}{10}\selectfont

\begin{tabular}{lrrlrl}
\toprule
Termo & Estimatica & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\alpha_1$ & 66,358 & 1,205 & [ 63,996 ; 68,721 ] & 55,056 & < 0.001\\
$\alpha_2$ & 55,373 & 1,002 & [ 53,409 ; 57,336 ] & 55,266 & < 0.001\\
$\alpha_3$ & 61,313 & 1,112 & [ 59,133 ; 63,492 ] & 55,147 & < 0.001\\
$\alpha_4$ & 51,004 & 0,921 & [ 49,199 ; 52,81 ] & 55,359 & < 0.001\\
$\alpha_5$ & 50,354 & 0,909 & [ 48,572 ; 52,137 ] & 55,373 & < 0.001\\
\addlinespace
$\beta$ & 9,699 & 0,648 & [ 8,428 ; 10,97 ] & 14,958 & < 0.001\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

Para o qual as estimação do parâmetro de precisão é $\phi = `r 1/dispersao.gamma`$ e tem um AIC = `r aic.gamma`.

## Diagnóstico do Modelo Gama

```{r}
# residuos gama
X <- model.matrix(snacks.fit.gamma.cos)
n <- nrow(X)
p <- ncol(X)
w <- snacks.fit.gamma.cos$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
fi <- gamma.shape(snacks.fit.gamma.cos)$alpha
ts <- resid(snacks.fit.gamma.cos,type="pearson")*sqrt(fi/(1-h))
td <- resid(snacks.fit.gamma.cos,type="deviance")*sqrt(fi/(1-h))
di <- (h/(1-h))*(ts^2)
a <- max(td)
b <- min(td)

grafico.residuo.gama <- tibble(fit = fitted(snacks.fit.gamma.cos), ts = ts) %>% ggplot(aes(x = fit, y = ts)) + geom_point()
grafico.deviance.gama <- tibble(fit = fitted(snacks.fit.gamma.cos), td = td) %>% ggplot(aes(x = fit, y = td)) + geom_point() + labs(y ="Resíduo Componente do Desvio", x = "Valores Ajustados")
grafico.residuo.index.gama <- tibble(index = 1:length(ts), ts = ts) %>% ggplot(aes(x = index, y = ts)) + geom_point()
grafico.deviance.index.gama <- tibble(index = 1:length(td), td = td) %>% ggplot(aes(x = index, y = td)) + geom_point() + labs(y ="Resíduo Componente do Desvio", x = "Índice")
grafico.deviance.density.gama <- tibble(fit = fitted(snacks.fit.gamma.cos), td = td) %>% ggplot(aes(x = td)) + geom_density() + labs(x ="Resíduo Componente do Desvio", y= "Densidade")
qqplot.deviance.gama <- td %>% enframe() %>%
  ggplot(aes(sample = value)) +
  stat_qq_band(bandType = "ts", fill = "#8DA0CB", alpha = 0.4) +
  stat_qq_line(colour = "#8DA0CB") +
  stat_qq_point() + labs(y ="Resíduo Componente do Desvio", x = "Percentil da N(0,1)")
grid.arrange(grafico.deviance.index.gama,grafico.deviance.gama, grafico.deviance.density.gama, qqplot.deviance.gama,
             ncol = 2, nrow = 2)
```

## Normal Inversa

Função de probabilidade

$$ f(y_{ijk},\mu_{ij},\phi) = exp\Bigg[\frac{-y_{ijk}/(2\phi\mu_{ij}) + 1/\mu}{\phi} - \frac{1}{2y_{ijk}\phi}-\frac{1}{2}log(2\pi\phi y^3_{ijk}) \Bigg] $$

Suposições:

- $Y_{ijk} \sim NI(\mu_{ij}\phi)$
- Indepência das observações
- Parâmetro de precisão $\phi$ constante

## Estimação dos parâmetros do modelo Normal Inversa 

```{r}
snacks.fit.ninv.cos1 <- snacks %>% mutate(week.cos = cos((-pi*week + 14*pi)/10)) %>%
  glm(texture ~ -1 + type * week.cos, family = inverse.gaussian(link = "identity"), .)
snacks.fit.ninv.cos2 <- snacks %>% mutate(week.cos = cos((-pi*week + 14*pi)/10)) %>%
  glm(texture ~ -1 + type + week.cos, family = inverse.gaussian(link = "identity"), .)
```

```{r}
param.ninv2 <- snacks.fit.ninv.cos2 %>% broom::tidy() %>%
  mutate(lower = estimate - std.error*1.96, upper = estimate + std.error*1.96) %>%
  mutate_if(is.numeric, funs(round(.,3))) %>%
  mutate(IC = paste("[",lower,";",upper,"]"),
                    p.value = if_else(p.value < 0.001, "< 0.001", as.character(p.value))) %>%
  dplyr::select(1:3,IC,statistic, p.value) %>%
  set_colnames(c("Termo", "Estimatica", "Erro Padrão", "IC (95%)", "Estatística t", "p-valor")) %>%
  kable("latex", booktabs = T) %>% kable_styling(font_size = 8)
dispersao.ninv2 <- round(summary(snacks.fit.ninv.cos2)$dispersion, 7)
aic.ninv2 <- round(snacks.fit.ninv.cos2$aic)
```

\begin{table}[H]
\centering\begingroup\fontsize{8}{10}\selectfont

\begin{tabular}{lrrlrl}
\toprule
Termo & Estimatica & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\alpha_1$ & 66,450 & 1,275 & [ 63,952 ; 68,948 ] & 52,134 & < 0.001\\
$\alpha_2$ & 55,406 & 0,965 & [ 53,514 ; 57,298 ] & 57,408 & < 0.001\\
$\alpha_3$ & 61,117 & 1,121 & [ 58,919 ; 63,314 ] & 54,516 & < 0.001\\
$\alpha_4$ & 51,012 & 0,852 & [ 49,342 ; 52,682 ] & 59,882 & < 0.001\\
$\alpha_5$ & 50,397 & 0,837 & [ 48,758 ; 52,037 ] & 60,245 & < 0.001\\
\addlinespace
$\beta$ & 9,699 & 0,634 & [ 8,456 ; 10,942 ] & 15,293 & < 0.001\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

Para o qual a estimação do parâmetro de precisão é $\phi = `r 1/dispersao.ninv2`$ e tem um AIC = `r aic.ninv2`.

## Diagnóstico do Modelo Normal Inversa

```{r}
X <- model.matrix(snacks.fit.ninv.cos2)
n <- nrow(X)
p <- ncol(X)
w <- snacks.fit.ninv.cos2$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
soma <- resid(snacks.fit.ninv.cos2, type="pearson")
soma <- sum(soma^2)
fi <- (n-p)/soma
ts <- resid(snacks.fit.ninv.cos2,type="pearson")*sqrt(fi/(1-h))
td <- resid(snacks.fit.ninv.cos2,type="deviance")*sqrt(fi/(1-h))
grafico.residuo.ninv2 <- tibble(fit = fitted(snacks.fit.ninv.cos2), ts = ts) %>% ggplot(aes(x = fit, y = ts)) + geom_point()
grafico.deviance.ninv2 <- tibble(fit = fitted(snacks.fit.ninv.cos2), td = td) %>% ggplot(aes(x = fit, y = td)) + geom_point() + labs(y ="Resíduo Componente do Desvio", x = "Valores Ajustados")
grafico.residuo.index.ninv2 <- tibble(index = 1:length(ts), ts = ts) %>% ggplot(aes(x = index, y = ts)) + geom_point()
grafico.deviance.index.ninv2 <- tibble(index = 1:length(td), td = td) %>% ggplot(aes(x = index, y = td)) + geom_point() + labs(y ="Resíduo Componente do Desvio", x = "Índice")
grafico.deviance.density.ninv2 <- tibble(fit = fitted(snacks.fit.ninv.cos2), td = td) %>% ggplot(aes(x = td)) + geom_density() + labs(x ="Resíduo Componente do Desvio", y= "Densidade")
qqplot.deviance.ninv2 <- td %>% enframe() %>%
  ggplot(aes(sample = value)) +
  stat_qq_band(bandType = "ts", fill = "#8DA0CB", alpha = 0.4) +
  stat_qq_line(colour = "#8DA0CB") +
  stat_qq_point() + labs(y ="Resíduo Componente do Desvio", x = "Percentil da N(0,1)")
grafico.hat.ninv2 <- tibble(h = h, fit = fitted(snacks.fit.ninv.cos2)) %>%
  ggplot(aes(x = fit, y = h)) + geom_point() + geom_hline(yintercept = sum(h)*2/750) +
  labs(y = "Medida H", x = "Valores ajustados")
grafico.cook.ninv2 <- tibble(c = di, fit = fitted(snacks.fit.ninv.cos2)) %>%
  ggplot(aes(x = fit, y = di)) + geom_point() +
  labs(y = "Distância de Cook", x = "Valores ajustados")
grid.arrange(grafico.deviance.index.ninv2,grafico.deviance.ninv2, grafico.deviance.density.ninv2, qqplot.deviance.ninv2,
             ncol = 2, nrow = 2)
```

## Comparação dos Resíduo Componente do Desvio para Gama e Normal Inversa

```{r}
grid.arrange(grafico.deviance.gama + labs(y ="Resíduo Componente do Desvio", x = "Valores Ajustados (Gama)"),
             grafico.deviance.ninv2 + labs(y ="Resíduo Componente do Desvio", x = "Valores Ajustados (NI)"),
             ncol = 2)
```

## Normal inversa com interação

$$ \mu_{ij} = \alpha_i + (\alpha\beta + \gamma_i)\cos(ax_j+b)$$

```{r}
estimativa.ninv.comint <- snacks.fit.ninv.cos1 %>% broom::tidy() %>%
  mutate(lower = estimate - std.error*1.96, upper = estimate + std.error*1.96) %>%
  mutate_if(is.numeric, funs(round(.,3))) %>%
  mutate(IC = paste("[",lower,";",upper,"]"),
                    p.value = if_else(p.value < 0.001, "< 0.001", as.character(p.value))) %>%
  dplyr::select(1:3,IC,statistic, p.value) %>%
  set_colnames(c("Termo", "Estimatica", "Erro Padrão", "IC (95%)", "Estatística t", "p-valor")) %>%
  kable("latex", booktabs = T) %>% kable_styling(font_size = 8)
dispersao.ninv1 <- round(summary(snacks.fit.ninv.cos2)$dispersion, 7)
aic.ninv1 <- round(snacks.fit.ninv.cos2$aic)
```

\begin{table}[H]
\centering\begingroup\fontsize{8}{10}\selectfont

\begin{tabular}{lrrlrl}
\toprule
Termo & Estimatica & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\alpha_1$ & 66,175 & 1,313 & [ 63,601 ; 68,749 ] & 50,384 & < 0.001\\
$\alpha_2$ & 55,302 & 1,012 & [ 53,318 ; 57,285 ] & 54,655 & < 0.001\\
$\alpha_3$ & 61,786 & 1,206 & [ 59,422 ; 64,149 ] & 51,237 & < 0.001\\
$\alpha_4$ & 50,988 & 0,900 & [ 49,224 ; 52,753 ] & 56,636 & < 0.001\\
$\alpha_5$ & 50,263 & 0,880 & [ 48,538 ; 51,988 ] & 57,117 & < 0.001\\
\addlinespace
$\alpha\beta$ & 8,449 & 1,835 & [ 4,852 ; 12,047 ] & 4,604 & < 0.001\\
$\gamma_2$ & 0,843 & 2,310 & [ -3,683 ; 5,37 ] & 0,365 & 0,715\\
$\gamma_3$ & 4,182 & 2,472 & [ -0,662 ; 9,026 ] & 1,692 & 0,091\\
$\gamma_4$ & 1,166 & 2,216 & [ -3,176 ; 5,509 ] & 0,526 & 0,599\\
$\gamma_5$ & 0,774 & 2,201 & [ -3,54 ; 5,088 ] & 0,352 & 0,725\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

Para o qual a estimação do parâmetro de precisão é $\phi = `r 1/dispersao.ninv1`$ e tem um AIC = `r aic.ninv1`.

## Influência e Alavanca

```{r}
grid.arrange(grafico.hat.ninv2, grafico.cook.ninv2, ncol=2)
```

## Intervalo de confiança

```{r}
# predicao
ilink <- family(snacks.fit.ninv.cos2)$linkin
pd <- snacks %>% group_by(type, week) %>% summarise(n = n()) %>% mutate(week.cos = cos((-pi*week + 14*pi)/10))
pd <- cbind(pd, predict(snacks.fit.ninv.cos2, pd, type = "link", se.fit=T)[1:2])
estimativa <- snacks.fit.ninv.cos2$coefficients
pd <- mutate(pd, mi = case_when(type == "A" ~ estimativa[1] + estimativa[6]*week.cos,
                                type == "B" ~ estimativa[2] + estimativa[6]*week.cos,
                                type == "C" ~ estimativa[3] + estimativa[6]*week.cos,
                                type == "D" ~ estimativa[4] + estimativa[6]*week.cos,
                                type == "E" ~ estimativa[5] + estimativa[6]*week.cos),
             dispersao = summary(snacks.fit.ninv.cos2)$dispersion)
pd <- mutate(pd, Fitted = ilink(fit),
             Upper = qinvgauss(0.975, mean = mi, dispersion = dispersao),
             Lower = qinvgauss(0.025, mean = mi, dispersion = dispersao),
             upper = ilink(fit + 1.96*se.fit),
             lower = ilink(fit - 1.96*se.fit))
pd <- cbind(pd, media = snacks %>% group_by(type,week) %>% summarise(media = mean(texture)) %>% pull(media))

ggplot() +
  geom_ribbon(data = pd, aes(ymin = lower, ymax = upper, x = week),
              fill = "red", alpha = 0.4) +
  geom_line(data = pd, aes(y = Fitted, x = week)) + facet_wrap(~ type) +
  geom_point(data = pd, aes(x = week, y = media)) +
  labs(x = "Semana", y = "Média")

```


```{r, eval = FALSE}
ggplot() +
  geom_ribbon(data = pd, aes(ymin = Lower, ymax = Upper, x = week),
              fill = "steelblue2", alpha = 0.5) +
  geom_line(data = pd, aes(y = Fitted, x = week)) + facet_wrap(~ type) +
  geom_point(data = snacks, aes(x = week, y = texture)) +
  labs(x = "Semana", y = "Cisalhamento")
```


## Sugestões de melhoria

- Outra distribuição talvez ajuste-se melhor aos dados, como um weibull ou log normal.
- Modelar também o parâmetro de precisão $\phi$, com um MLG duplo.
- Utilizar outros modelos como o GAM ou GAMLSS.

## Bibliografia

Azevedo, C. L. N. *Notas de Aula ME613*. Dispónivel em:https://www.ime.unicamp.br/~cnaber/Material_ME613_1S_2019.htm

Azevedo, C. L. N. *Notas de Aula ME720*. Dispónivel em:https://www.ime.unicamp.br/~cnaber/Material_MLG_1S_2016.htm

Paula, GA (2013) **Modelos de regressão com apoio computacional**. Dispónivel em:https://www.ime.usp.br/~giapaula/texto_2013.pdf

McCullagh, P. e Nelder, J. A. 1989. **Generalized Linear Models**. Chapman and Hall

Jong, P. e Heller, G. Z. **Generalized Linear Models for Insurancer Data**. Cambridge University Press

Vanegas, L. H. e Paula, G. A. (2016). ssym: Fitting Semi-Parametric log-Symmetric Regression Models. R package version 1.5.7. https://CRAN.R-project.org/package=ssym

